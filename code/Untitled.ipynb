{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "stupid-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join('..','data','experiment_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-chicken",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 'Very intuitive, an explanation I could give or expect'\n",
    "second_best = 'Intuitive'\n",
    "middle = 'Neither intuitive or unintuitive'\n",
    "second_worst = 'Unintuitive'\n",
    "worst = 'Not intuitive at all, not an explanation I would give or expect'\n",
    "\n",
    "data = data.replace(best,5).replace(second_best,4).replace(middle,3).replace(second_worst,2).replace(worst,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-temperature",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_questions = data.iloc[:,1:4]\n",
    "filter_questions.columns = ['Native_Language', 'Nationality','Gender']\n",
    "#filter_questions = filter_questions.iloc[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxed-range",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_questions[filter_questions['Native_Language'] == 'English']\n",
    "filter_questions['Native_Language'] = filter_questions['Native_Language'].apply(lambda x:x.title())\n",
    "filter_questions['Nationality'] = filter_questions['Nationality'].apply(lambda x:x.title())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_questions.groupby(by=['Nationality','Native_Language']).agg(['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in data.columns if \n",
    "        (col != 'Timestamp') and ('Optional' not in col) \n",
    "                and (not col.startswith('Do') and (not col.startswith('What'))\n",
    "                and (not col.startswith('Any')) and (not col.startswith('Unnamed')))]\n",
    "\n",
    "#drop great grandparent\n",
    "cols = cols[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-devon",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = data.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols = [\n",
    "    'aunt_aunt_brother',\n",
    "    'aunt_grandparent_child',\n",
    "    'aunt_sister_parent',\n",
    "    'aunt_aunt_sister',\n",
    "    'uncle_brother_uncle',\n",
    "    'uncle_grandparent_child',\n",
    "    'uncle_parent_brother',\n",
    "    'uncle_uncle_sister',\n",
    "    'spouse_spouse',\n",
    "    'spouse_child_parent',\n",
    "    'brother_uncle_child',\n",
    "    'brother_parent_child',\n",
    "    'brother_sister_brother',\n",
    "    'brother_aunt_aunt',\n",
    "    'brother_grandparent_grandparent',\n",
    "    'brother_parent_parent',\n",
    "    'brother_sister_sister',\n",
    "    'brother_uncle_uncle',\n",
    "    'sister_brother',\n",
    "    'sister_brother_sister',\n",
    "    'sister_child_aunt',\n",
    "    'sister_parent_child',\n",
    "    'sister_aunt_aunt',\n",
    "    'sister_brother_brother',\n",
    "    'sister_grandparent_grandparent',\n",
    "    'sister_parent_parent',\n",
    "    'sister_uncle_uncle',\n",
    "    'grandparent_brother_grandparent',\n",
    "    'grandparent_grandparent_spouse',\n",
    "    'grandparent_parent_parent',\n",
    "    'grandparent_sister_grandparent',\n",
    "    'grandparent_aunt_child',\n",
    "    'grandparent_parent_child',\n",
    "    'grandparent_uncle_child',\n",
    "    'grandparent_child_child',\n",
    "    'child_child_sister',\n",
    "    'child_brother_uncle',\n",
    "    'child_child_brother',\n",
    "    'child_parent_grandparent',\n",
    "    'child_sister_aunt',\n",
    "    'child_spouse_parent',\n",
    "    'child_parent',\n",
    "    'child_aunt_brother',\n",
    "    'child_brother_parent',\n",
    "    'child_grandparent_child',\n",
    "    'child_sister_parent',\n",
    "    'parent_brother_parent',\n",
    "    'parent_child_grandparent',\n",
    "    'parent_parent_spouse',\n",
    "    'parent_sister_parent',\n",
    "    'parent_aunt_sister',\n",
    "    'parent_brother_child',\n",
    "    'parent_grandparent_parent',\n",
    "    'parent_sister_child',\n",
    "    'parent_uncle_brother',\n",
    "    'parent_child',\n",
    "    'parent_spouse_child'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict((clean_data/5).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data.columns = all_cols\n",
    "values = (clean_data).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-maximum",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full = pd.concat([filter_questions,clean_data],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-algorithm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full.groupby(by=['Nationality','Native_Language']).agg(['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-visit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_weights = dict((clean_data/5).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('..','data','predicate_weights.json'),'w') as f:\n",
    "    json.dump(predicate_weights,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-enterprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {'Français':'French','Française':'French'}\n",
    "\n",
    "filter_questions = filter_questions.replace(replace_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-colonial",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-interface",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import spearmanr\n",
    "\n",
    "# rho, _ = spearmanr(clean_data[filter_questions['Native_Language']=='French'].mean(axis=0),\n",
    "#                   clean_data[filter_questions['Native_Language']=='English'].mean(axis=0))\n",
    "\n",
    "# print(rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "stat, p = mannwhitneyu(clean_data[filter_questions['Native_Language']=='French'].mean(axis=0),\n",
    "                       clean_data[filter_questions['Native_Language']=='English'].mean(axis=0))\n",
    "\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Probably the same distribution')\n",
    "else:\n",
    "    print('Probably different distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "stat, p = ttest_ind(clean_data[filter_questions['Native_Language']=='French'].mean(axis=0),\n",
    "                       clean_data[filter_questions['Native_Language']=='English'].mean(axis=0))\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Probably the same distribution')\n",
    "else:\n",
    "    print('Probably different distributions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(values):\n",
    "    \n",
    "    std_error = np.std(values, ddof=1) / np.sqrt(len(values))\n",
    "    \n",
    "    ticks = np.arange(len(values))\n",
    "    \n",
    "    explanations = []\n",
    "\n",
    "    for i in values.index:\n",
    "\n",
    "        split_str = i.split('_')\n",
    "\n",
    "        relation = split_str[0]\n",
    "        \n",
    "        explanations.append('_'.join(split_str[1:]))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10,4))\n",
    "\n",
    "    ax.bar(x=ticks, \n",
    "           height=values,\n",
    "           yerr=std_error,\n",
    "          capsize=4)\n",
    "    \n",
    "    ax.set_xticks(ticks=ticks)\n",
    "    ax.set_xticklabels(labels=explanations,rotation = (45), fontsize = 10)\n",
    "    \n",
    "    ax.set_title(relation.title())\n",
    "    plt.savefig(os.path.join('..','plots',f\"{relation}.pdf\"),bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minus-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(values[0:4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(values[4:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(values[8:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(values[10:18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(values[18:27])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-kansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(values[27:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-chapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(values[35:46])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contemporary-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_plot(values[46:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-trouble",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "wanted-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-rating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "requested-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'paul_dataset'\n",
    "RULE = 'spouse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "accomplished-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(os.path.join('..','data',DATASET+'.npz'))\n",
    "\n",
    "triples,traces,weights,entities,relations = utils.get_data(data,RULE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "permanent-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ENTITIES = len(entities)\n",
    "NUM_RELATIONS = len(relations)\n",
    "\n",
    "ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "rel2idx = dict(zip(relations, range(NUM_RELATIONS)))\n",
    "\n",
    "idx2ent = dict(zip(range(NUM_ENTITIES),entities))\n",
    "idx2rel = dict(zip(range(NUM_RELATIONS),relations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amateur-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevance_scores = {}\n",
    "\n",
    "# for i in range(len(traces)):\n",
    "    \n",
    "#     stripped_trace = utils.remove_padding_np(traces[i])\n",
    "    \n",
    "# #     if str(stripped_trace) in relevance_scores:\n",
    "# #         print(stripped_trace)\n",
    "        \n",
    "#     predicate = '_'.join(stripped_trace[:,1])\n",
    "\n",
    "#     relevance_scores[str(stripped_trace)] = {predicate:weights[i]}\n",
    "    \n",
    "# relevance_scores[str(utils.remove_padding_np(traces[i]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "framed-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_scores = utils.get_relevance_scores(\n",
    "    utils.array2idx(traces,ent2idx,rel2idx),\n",
    "    weights,\n",
    "    ent2idx['UNK_ENT'],\n",
    "    rel2idx['UNK_REL']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-lender",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-syndication",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-quebec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dietary-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_exp = utils.remove_padding_np(\n",
    "    utils.array2idx(traces[3],ent2idx,rel2idx),\n",
    "    ent2idx['UNK_ENT'],\n",
    "    rel2idx['UNK_REL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_g_precision(true_exp,pred_exp,relevance_scores):\n",
    "    \n",
    "#     n = len(pred_exp)\n",
    "\n",
    "#     if np.issubdtype(true_exp.dtype, np.integer):\n",
    "#         relation_key = '_'.join([str(i) for i in true_exp[:,1]])\n",
    "#     else:\n",
    "#         relation_key = '_'.join(true_exp[:,1])\n",
    "        \n",
    "#     g_precision = 0.0\n",
    "    \n",
    "#     for i in range(n):\n",
    "        \n",
    "#         triple = pred_exp[i]\n",
    "        \n",
    "#         rel_score = relevance_scores[str(triple)][relation_key]\n",
    "        \n",
    "#         g_precision += rel_score\n",
    "        \n",
    "#     return g_precision / n\n",
    "\n",
    "def get_g_recall(pred_exp,relevance_scores):\n",
    "    \n",
    "    pred_relevance = 0.0\n",
    "    total_relevance = relevance_scores.values()\n",
    "    \n",
    "    for i in range(len(pred_exp)):\n",
    "        \n",
    "        triple = pred_exp[i]\n",
    "        \n",
    "        rel_score = relevance_scores[str(triple)]\n",
    "        \n",
    "        pred_relevance += rel_score\n",
    "        \n",
    "    return pred_relevance / (total_relevance - pred_relevance)\n",
    "\n",
    "def get_g_recall(pred_exp,relevance_scores):\n",
    "    \n",
    "    pred_relevance = 0.0\n",
    "    total_relevance = relevance_scores.values()\n",
    "    \n",
    "    for i in range(len(pred_exp)):\n",
    "        \n",
    "        triple = pred_exp[i]\n",
    "        \n",
    "        rel_score = relevance_scores[str(triple)]\n",
    "        \n",
    "        pred_relevance += rel_score\n",
    "        \n",
    "    return pred_relevance / total_relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-service",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-capacity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-notification",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
