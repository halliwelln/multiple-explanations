{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "subtle-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "solved-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'simpsons'\n",
    "rules = ['child','parent','spouse','brother','sister','grandparent', 'full_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "south-generic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "child: 255\n",
      "parent: 254\n",
      "spouse: 70\n",
      "brother: 576\n",
      "sister: 482\n",
      "grandparent: 168\n",
      "full_data: 1805\n"
     ]
    }
   ],
   "source": [
    "counts = dict(zip(rules,np.zeros(len(rules))))\n",
    "counts['UNK_REL'] = 0\n",
    "\n",
    "for rule in rules:\n",
    "    \n",
    "    data = np.load(os.path.join('..','data',DATASET+'.npz'))\n",
    "\n",
    "    triples,traces,weights,entities,relations = utils.get_data(data,rule)\n",
    "    \n",
    "    num_triples = triples.shape[0]\n",
    "    \n",
    "    print(f'{rule}: {num_triples}')\n",
    "    counts[rule] += triples.shape[0]\n",
    "    counts[rule + '_num_entities'] = len(entities)\n",
    "\n",
    "    for i in range(len(traces)):\n",
    "\n",
    "        for j in range(len(traces[i])):\n",
    "            \n",
    "            for k in range(len(traces[i,j])):\n",
    "                \n",
    "                rel = traces[i,j,k][1]\n",
    "                \n",
    "                counts[rel] += 1\n",
    "            \n",
    "#             rels = traces[i,j][:,1]\n",
    "        \n",
    "#             if (rels == 'UNK_REL').sum() != 2 :\n",
    "\n",
    "#                 rels = '_'.join(rels)\n",
    "                \n",
    "#                 if rels in counts:\n",
    "#                     counts[rels] += 1\n",
    "#                 else:\n",
    "#                     counts[rels] = 1\n",
    "#     print('\\n')              \n",
    "#     print(f'rule {rule} counts: {counts}')\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bored-aerospace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'child': 17001.0,\n",
       " 'parent': 22366.0,\n",
       " 'spouse': 2122.0,\n",
       " 'brother': 84936.0,\n",
       " 'sister': 78580.0,\n",
       " 'grandparent': 14912.0,\n",
       " 'full_data': 1805.0,\n",
       " 'UNK_REL': 251712,\n",
       " 'child_num_entities': 169,\n",
       " 'parent_num_entities': 169,\n",
       " 'spouse_num_entities': 159,\n",
       " 'brother_num_entities': 135,\n",
       " 'sister_num_entities': 114,\n",
       " 'grandparent_num_entities': 127,\n",
       " 'full_data_num_entities': 180}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "disciplinary-ghana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219917.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for rule in rules:\n",
    "    total += counts[rule]\n",
    "total - counts['full_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-titanium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exterior-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'parent'    \n",
    "\n",
    "data = np.load(os.path.join('..','data',DATASET+'.npz'))\n",
    "\n",
    "triples,traces,weights,entities,relations = utils.get_data(data,RULE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-princess",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "difficult-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_data = np.load(\n",
    "    os.path.join('..','data','preds',DATASET,\n",
    "        'gnn_explainer_'+DATASET+'_'+RULE+'_preds.npz'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wrapped-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_ENT_ID = 'UNK_ENT'\n",
    "UNK_REL_ID = 'UNK_REL'\n",
    "UNK_WEIGHT_ID = 'UNK_WEIGHT'\n",
    "MAX_TRACE = data['max_trace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "chronic-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_test_idx = gnn_data['test_idx']\n",
    "gnn_true_triples = triples[gnn_test_idx]\n",
    "gnn_true_exps = traces[gnn_test_idx]\n",
    "gnn_true_weights = weights[gnn_test_idx]\n",
    "\n",
    "gnn_preds = gnn_data['preds']\n",
    "\n",
    "num_gnn_triples = gnn_true_exps.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "immediate-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_counts = {}\n",
    "\n",
    "for i in range(num_gnn_triples):\n",
    "    \n",
    "    gnn_true_triple = gnn_true_triples[i]\n",
    "    gnn_true_exp = gnn_true_exps[i]\n",
    "    gnn_pred = gnn_preds[i]\n",
    "    true_weight = gnn_true_weights[i]\n",
    "    \n",
    "    _,max_idx = utils.max_jaccard_np(gnn_true_exp,gnn_pred,UNK_ENT_ID,UNK_REL_ID,return_idx=True)\n",
    "    \n",
    "    max_predicates = gnn_true_triple[1] +'_' + '_'.join([p for p in gnn_true_exp[max_idx,:,1] if p != 'UNK_REL'])\n",
    "    \n",
    "    if max_predicates in predicate_counts:\n",
    "        predicate_counts[max_predicates] += 1\n",
    "    else:\n",
    "        predicate_counts[max_predicates] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "proved-phoenix",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('..','data','predicate_weights.json'),'r') as f:\n",
    "    predicate_weights = json.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "formal-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_counts = {}\n",
    "\n",
    "for k,count in predicate_counts.items():\n",
    "    \n",
    "    str_weight = predicate_weights[k]\n",
    "    \n",
    "    if str_weight in weight_counts:\n",
    "        weight_counts[str_weight] += count\n",
    "    else:\n",
    "        weight_counts[str_weight] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "considered-services",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.9: 9, 0.7: 67, 0.3: 9}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "concerned-status",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parent_child': 9,\n",
       " 'parent_brother_child': 13,\n",
       " 'parent_child_spouse': 8,\n",
       " 'parent_brother_parent': 17,\n",
       " 'parent_grandparent_parent': 2,\n",
       " 'parent_parent_spouse': 8,\n",
       " 'parent_child_sister': 17,\n",
       " 'parent_parent_sister': 4,\n",
       " 'parent_child_grandparent': 7}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicate_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_sum = []\n",
    "\n",
    "# for i in range(len(weights[0])):\n",
    "    \n",
    "#     summm = 0.0\n",
    "    \n",
    "#     for j in weights[0][i]:\n",
    "        \n",
    "#         if j != 'UNK_WEIGHT':\n",
    "#             summm += float(j)\n",
    "#     weight_sum.append(summm)\n",
    "\n",
    "# weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-wrong",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-salad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-carol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-planet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-dating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-employer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-penetration",
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'spouse'\n",
    "\n",
    "data = np.load(os.path.join('..','data',DATASET+'.npz'))\n",
    "\n",
    "triples,traces,weights,entities,relations = utils.get_data(data,RULE)\n",
    "\n",
    "explaine_data = np.load(\n",
    "    os.path.join('..','data','preds',DATASET,\n",
    "        'explaine_'+DATASET+'_'+RULE+'_preds.npz'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-luxembourg",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "print(explaine_data['preds'][i])\n",
    "print()\n",
    "print()\n",
    "triples[explaine_data['test_idx']][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-steel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import RGCN\n",
    "\n",
    "# model = RGCN.get_RGCN_Model(\n",
    "#     num_entities=len(entities),\n",
    "#     num_relations=len(relations),\n",
    "#     embedding_dim=3,\n",
    "#     output_dim=3,\n",
    "#     seed=123\n",
    "# )\n",
    "\n",
    "# model.load_weights(os.path.join('..','data','weights',DATASET,DATASET+'_'+RULE+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-blackberry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-archive",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "administrative-finder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-worship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-sewing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-calendar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-point",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-vitamin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pretty-recycling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-speed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-vintage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-outdoors",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-privacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-heritage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-burns",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-typing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, XML\n",
    "from rdflib import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 1000\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(f\"\"\"\n",
    "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "    PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "    CONSTRUCT{{\n",
    "    ?x\n",
    "    dbo:child ?child .\n",
    "    }}\n",
    "    WHERE {{\n",
    "    ?x a dbo:Royalty .\n",
    "    OPTIONAL {{?x dbo:child ?child }}\n",
    "    }}\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-request",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "severe-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql.setReturnFormat(XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sparql.query().convert().serialize(destination='/Users/nhalliwe/Desktop/test',\n",
    "            format='xml'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "# PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "\n",
    "# CONSTRUCT{ \n",
    "#      ?x dbo:parent ?parent ;\n",
    "#      dbo:child ?child ;\n",
    "#      dbo:spouse ?spouse ;\n",
    "#      foaf:gender ?gender ;\n",
    "#  }\n",
    "# WHERE {\n",
    "#   OPTIONAL {?x dbo:parent ?parent }\n",
    "#   OPTIONAL {?x dbo:spouse ?spousea }\n",
    "#   OPTIONAL {?x foaf:gender ?gender }\n",
    "#   OPTIONAL {?x dbo:child ?child } \n",
    "\n",
    "#   FILTER regex(?x,\"England\")\n",
    "# }\n",
    "#rename file with .ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-johnston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "# PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "\n",
    "# CONSTRUCT{ \n",
    "#      ?x dbo:parent ?parent ;\n",
    "#      dbo:child ?child ;\n",
    "#      dbo:spouse ?spouse ;\n",
    "#      foaf:gender ?gender ;\n",
    "#  }\n",
    "# WHERE {\n",
    "#   ?x dbo:parent ?parent .\n",
    "#   ?x dbo:spouse ?spouse .\n",
    "#   ?x foaf:gender ?gender .\n",
    "#   ?x dbo:child ?child .\n",
    "\n",
    "#   FILTER regex(?x,\"England\")\n",
    "# }\n",
    "#small english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rising-awareness",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from rdflib import plugin\n",
    "import rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "plugin.register(\n",
    "    'sparql', rdflib.query.Processor,\n",
    "    'rdfextras.sparql.processor', 'Processor')\n",
    "plugin.register(\n",
    "    'sparql', rdflib.query.Result,\n",
    "    'rdfextras.sparql.query', 'SPARQLQueryResult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-croatia",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph(base='http://www.w3.org/2000/01/rdf-schema#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.parse('/Users/nhalliwe/Desktop/full_test',format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "    \n",
    "CONSTRUCT{{\n",
    "    ?x\n",
    "    dbo:parent ?parent ;\n",
    "    dbo:child ?child ;\n",
    "    dbo:spouse ?spouse ;\n",
    "    foaf:gender ?gender .\n",
    "    }}\n",
    "WHERE {{\n",
    "    ?x a dbo:Royalty .\n",
    "    OPTIONAL {{?x dbo:parent ?parent }}\n",
    "    OPTIONAL {{?x dbo:spouse ?spouse }}\n",
    "    OPTIONAL {{?x foaf:gender ?gender }}\n",
    "    OPTIONAL {{?x dbo:child ?child }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-dimension",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in g.query(query):Âµ\n",
    "#     print(row['*'])\n",
    "\n",
    "g.query(query)#.serialize(destination='/Users/nhalliwe/Desktop/test',format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.parse('/Users/nhalliwe/Desktop/Explain-KG/data/rules/full_royalty',format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-bibliography",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.parse('/Users/nhalliwe/Desktop/test',format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-strap",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.serialize(destination='/Users/nhalliwe/Desktop/full_test',format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-protection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-attraction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-blackjack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# triple_lookup = {}\n",
    "# longest_trace = -1\n",
    "# max_padding = 3\n",
    "\n",
    "# for i in unique_idx:\n",
    "    \n",
    "#     triple = triples[i]\n",
    "    \n",
    "#     indices = (triples == triple).all(axis=1)\n",
    "        \n",
    "#     triple_lookup[str(triple)] = indices\n",
    "    \n",
    "#     sum_indices = indices.sum()\n",
    "    \n",
    "#     if sum_indices > longest_trace:\n",
    "        \n",
    "#         longest_trace = sum_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-michigan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_triples = []\n",
    "# processed_weights = []\n",
    "# processed_traces = []\n",
    "# unk = np.array([['UNK_ENT','UNK_REL','UNK_ENT']])\n",
    "# unk_weight_str = 'UNK_WEIGHT'\n",
    "# unk_weight = np.array([[unk_weight_str] * max_padding])\n",
    "\n",
    "# for idx in unique_idx:\n",
    "    \n",
    "#     triple = triples[idx]\n",
    "    \n",
    "#     trace_indices = triple_lookup[str(triple)]\n",
    "#     trace = traces[trace_indices]\n",
    "#     weight = weights[trace_indices]\n",
    "    \n",
    "#     per_trace_weights = []\n",
    "\n",
    "#     for i in range(len(trace)):\n",
    "\n",
    "#         num_triples = trace[i].shape[0]\n",
    "#         current_weight = weights[trace_indices][i]\n",
    "\n",
    "#         num_unk = (trace[i] == unk).all(axis=1).sum()\n",
    "\n",
    "#         current_weights = [current_weight] * (num_triples-num_unk)\n",
    "\n",
    "#         while len(current_weights) != num_triples:\n",
    "\n",
    "#             current_weights.append(unk_weight_str)\n",
    "            \n",
    "#         per_trace_weights.append(current_weights)\n",
    "          \n",
    "#     per_trace_weights = np.array(per_trace_weights)\n",
    "    \n",
    "#     while per_trace_weights.shape[0] != longest_trace:\n",
    "#         per_trace_weights = np.concatenate([per_trace_weights,unk_weight],axis=0)\n",
    "        \n",
    "#     padded_trace = utils.pad_trace(trace,max_padding=max_padding,longest_trace=longest_trace,unk=unk)\n",
    "    \n",
    "#     processed_triples.append(triple)\n",
    "#     processed_traces.append(padded_trace)\n",
    "#     processed_weights.append(per_trace_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-collect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_triples = np.array(processed_triples)\n",
    "# all_traces = np.array(processed_traces)\n",
    "# all_weights = np.array(processed_weights)\n",
    "#traces: (NUM_TRIPLES,LONGEST_TRACE,MAX_PADDING,3)\n",
    "#weights: (NUM_TRIPLES,LONGEST_TRACE,MAX_PADDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-weather",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-atlas",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-pearl",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 2\n",
    "# current_traces = all_traces[idx]\n",
    "# current_weights = all_weights[idx]\n",
    "\n",
    "### pred_exp = np.array([['<http://example.org/data#MotherPaul>', 'child',\n",
    "#          '<http://example.org/data#BrotherPaul>'],\n",
    "#         ['<http://example.org/data#FatherPaul>', 'child',\n",
    "#          '<http://example.org/data#BrotherPaul>']\n",
    "#         ])\n",
    "\n",
    "# pred_exp = np.array(\n",
    "#     [['<http://example.org/data#MotherPaul>', 'spouse',\n",
    "#          '<http://example.org/data#FatherPaul>']])\n",
    "# def precision_recall(pred_exp,current_traces,current_weights):\n",
    "    \n",
    "#     n = len(pred_exp)\n",
    "\n",
    "#     relevance_scores = np.zeros(longest_trace) #numerator of graded recall\n",
    "\n",
    "#     for i in range(n):\n",
    "\n",
    "#         current_pred = pred_exp[i]\n",
    "\n",
    "#         for j in range(len(current_traces)):\n",
    "\n",
    "#             unpadded_traces = remove_padding_np(current_traces[j],'UNK_ENT','UNK_REL')\n",
    "#             unpadded_weights = current_weights[j][current_weights[j] != 'UNK_WEIGHT']\n",
    "\n",
    "#             indices = (unpadded_traces == current_pred).all(axis=1)\n",
    "\n",
    "#             sum_weights = sum([float(num) for num in unpadded_weights[indices]])\n",
    "\n",
    "#             relevance_scores[j] += sum_weights\n",
    "\n",
    "#     max_relevance_score = max(relevance_scores)\n",
    "#     max_idx = np.argmax(relevance_scores)\n",
    "\n",
    "#     total_sum = sum([float(weight) for weight in current_weights[max_idx] if weight != 'UNK_WEIGHT'])\n",
    "\n",
    "#     precision = max_relevance_score/n\n",
    "#     recall = max_relevance_score/total_sum\n",
    "    \n",
    "#     return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-abuse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-basics",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d1,d2,_ = (all_traces[2] != ['UNK_ENT','UNK_REL','UNK_ENT']).nonzero()\n",
    "#all_traces[2][d1,d2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_pred_exp = tf.convert_to_tensor(pred_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-dublin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_traces_i = tf.convert_to_tensor(all_traces[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-messenger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-scout",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "#triples2idx = utils.array2idx(all_triples,ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "macro-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traces2idx = utils.array2idx(all_traces,ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-stamp",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "czech-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RGCN.get_RGCN_Model(\n",
    "#     num_entities=NUM_ENTITIES,\n",
    "#     num_relations=NUM_RELATIONS,\n",
    "#     embedding_dim=10,\n",
    "#     output_dim=10,\n",
    "#     seed=123\n",
    "# )\n",
    "\n",
    "# model.load_weights(os.path.join('..','data','weights',DATASET,DATASET+'_'+RULE+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organizational-instruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_INDICES = tf.reshape(tf.range(0,NUM_ENTITIES,1,dtype=tf.int64), (1,-1))\n",
    "\n",
    "# ADJACENCY_DATA = tf.concat([triples2idx,traces2idx.reshape(-1,3)],axis=0)\n",
    "# adj_mats = utils.get_adj_mats(ADJACENCY_DATA,NUM_ENTITIES,NUM_RELATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-liability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-stanford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-consumption",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-graduate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
