{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "marked-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "contemporary-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'paul_dataset'\n",
    "RULE = 'brother'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sixth-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_file = 'brother_sister'\n",
    "MAX_PADDING = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exempt-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "triples,traces, weights = utils.parse_ttl(\n",
    "    file_name=os.path.join('..','data','traces',rule_file+'.ttl'),\n",
    "    max_padding=MAX_PADDING\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "august-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, unique_traces_idx = np.unique(traces, axis=0,return_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "happy-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = triples[unique_traces_idx]\n",
    "traces = traces[unique_traces_idx]\n",
    "weights = weights[unique_traces_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accessible-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rule_file == 'brother_sister':\n",
    "\n",
    "    gender_indices = (traces[:,:,1] == 'gender').any(axis=1)\n",
    "\n",
    "    triples = triples[~gender_indices]\n",
    "    traces = traces[~gender_indices]\n",
    "    weights = weights[~gender_indices]\n",
    "\n",
    "    MAX_PADDING = 2\n",
    "    \n",
    "    traces = traces[:,0:MAX_PADDING,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "organized-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK = np.array([['UNK_ENT','UNK_REL','UNK_ENT']])\n",
    "UNK_WEIGHT_STR = 'UNK_WEIGHT'\n",
    "UNK_WEIGHT = np.array([[UNK_WEIGHT_STR] * MAX_PADDING])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "incredible-mission",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, unique_triples_idx = np.unique(triples,axis=0,return_index=True)\n",
    "\n",
    "triple_lookup = {}\n",
    "longest_trace = -1\n",
    "\n",
    "for i in unique_triples_idx:\n",
    "\n",
    "    triple = triples[i]\n",
    "\n",
    "    indices = (triples == triple).all(axis=1)\n",
    "\n",
    "    triple_lookup[str(triple)] = indices\n",
    "\n",
    "    sum_indices = indices.sum()\n",
    "\n",
    "    if sum_indices > longest_trace:\n",
    "\n",
    "        longest_trace = sum_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "elegant-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_triples = []\n",
    "processed_weights = []\n",
    "processed_traces = []\n",
    "\n",
    "for idx in unique_triples_idx:\n",
    "\n",
    "    triple = triples[idx]\n",
    "\n",
    "    trace_indices = triple_lookup[str(triple)]\n",
    "    trace = traces[trace_indices]\n",
    "    weight = weights[trace_indices]\n",
    "\n",
    "    per_trace_weights = []\n",
    "\n",
    "    for i in range(len(trace)):\n",
    "\n",
    "        num_triples = trace[i].shape[0]\n",
    "        current_weight = weights[trace_indices][i]\n",
    "\n",
    "        num_unk = (trace[i] == UNK).all(axis=1).sum()\n",
    "\n",
    "        current_weights = [current_weight] * (num_triples-num_unk)\n",
    "\n",
    "        while len(current_weights) != num_triples:\n",
    "\n",
    "            current_weights.append(UNK_WEIGHT_STR)\n",
    "\n",
    "        per_trace_weights.append(current_weights)\n",
    "\n",
    "    per_trace_weights = np.array(per_trace_weights)\n",
    "\n",
    "    while per_trace_weights.shape[0] != longest_trace:\n",
    "        per_trace_weights = np.concatenate([per_trace_weights,UNK_WEIGHT],axis=0)\n",
    "\n",
    "    padded_trace = utils.pad_trace(trace,max_padding=MAX_PADDING,longest_trace=longest_trace,unk=UNK)\n",
    "\n",
    "    processed_triples.append(triple)\n",
    "    processed_traces.append(padded_trace)\n",
    "    processed_weights.append(per_trace_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "comprehensive-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "del triples\n",
    "del traces\n",
    "del weights\n",
    "\n",
    "triples = np.array(processed_triples)\n",
    "traces = np.array(processed_traces)\n",
    "weights = np.array(processed_weights)\n",
    "\n",
    "del processed_triples\n",
    "del processed_traces\n",
    "del processed_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-kentucky",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-grave",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "hidden-portrait",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[['<http://example.org/data#AuntPaul1>', 'sister',\n",
       "         '<http://example.org/data#UnclePaul1>'],\n",
       "        ['<http://example.org/data#UnclePaul1>', 'brother',\n",
       "         '<http://example.org/data#FatherPaul>']],\n",
       "\n",
       "       [['<http://example.org/data#FatherPaul>', 'sister',\n",
       "         '<http://example.org/data#UnclePaul1>'],\n",
       "        ['<http://example.org/data#AuntPaul1>', 'sister',\n",
       "         '<http://example.org/data#UnclePaul1>']],\n",
       "\n",
       "       [['UNK_ENT', 'UNK_REL', 'UNK_ENT'],\n",
       "        ['UNK_ENT', 'UNK_REL', 'UNK_ENT']],\n",
       "\n",
       "       [['UNK_ENT', 'UNK_REL', 'UNK_ENT'],\n",
       "        ['UNK_ENT', 'UNK_REL', 'UNK_ENT']],\n",
       "\n",
       "       [['UNK_ENT', 'UNK_REL', 'UNK_ENT'],\n",
       "        ['UNK_ENT', 'UNK_REL', 'UNK_ENT']],\n",
       "\n",
       "       [['UNK_ENT', 'UNK_REL', 'UNK_ENT'],\n",
       "        ['UNK_ENT', 'UNK_REL', 'UNK_ENT']],\n",
       "\n",
       "       [['UNK_ENT', 'UNK_REL', 'UNK_ENT'],\n",
       "        ['UNK_ENT', 'UNK_REL', 'UNK_ENT']],\n",
       "\n",
       "       [['UNK_ENT', 'UNK_REL', 'UNK_ENT'],\n",
       "        ['UNK_ENT', 'UNK_REL', 'UNK_ENT']]], dtype='<U42')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.pad_trace(traces[0],2,8,UNK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-infrared",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-aruba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-maple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-respect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-eligibility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-african",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.load(os.path.join('..','data',DATASET+'.npz'))\n",
    "\n",
    "# triples,traces,weights,entities,relations = utils.get_data(data,RULE)\n",
    "\n",
    "# NUM_ENTITIES = len(entities)\n",
    "# NUM_RELATIONS = len(relations)\n",
    "\n",
    "# ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "# rel2idx = dict(zip(relations, range(NUM_RELATIONS)))\n",
    "\n",
    "# idx2ent = dict(zip(range(NUM_ENTITIES),entities))\n",
    "# idx2rel = dict(zip(range(NUM_RELATIONS),relations))\n",
    "\n",
    "# unk_ent_id = ent2idx['UNK_ENT']\n",
    "# unk_rel_id = rel2idx['UNK_REL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-title",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = np.array([.99,.99,.5,.5,.5,.99,.5,.99,.5,.99,.5,.99,.5,.99,.5,.5,.5,.99,.5,.5,.99,.99,.99,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_,unique_idx = np.unique(triples,axis=0,return_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-charter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# triple_lookup = {}\n",
    "# longest_trace = -1\n",
    "# max_padding = 3\n",
    "\n",
    "# for i in unique_idx:\n",
    "    \n",
    "#     triple = triples[i]\n",
    "    \n",
    "#     indices = (triples == triple).all(axis=1)\n",
    "        \n",
    "#     triple_lookup[str(triple)] = indices\n",
    "    \n",
    "#     sum_indices = indices.sum()\n",
    "    \n",
    "#     if sum_indices > longest_trace:\n",
    "        \n",
    "#         longest_trace = sum_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_triples = []\n",
    "# processed_weights = []\n",
    "# processed_traces = []\n",
    "# unk = np.array([['UNK_ENT','UNK_REL','UNK_ENT']])\n",
    "# unk_weight_str = 'UNK_WEIGHT'\n",
    "# unk_weight = np.array([[unk_weight_str] * max_padding])\n",
    "\n",
    "# for idx in unique_idx:\n",
    "    \n",
    "#     triple = triples[idx]\n",
    "    \n",
    "#     trace_indices = triple_lookup[str(triple)]\n",
    "#     trace = traces[trace_indices]\n",
    "#     weight = weights[trace_indices]\n",
    "    \n",
    "#     per_trace_weights = []\n",
    "\n",
    "#     for i in range(len(trace)):\n",
    "\n",
    "#         num_triples = trace[i].shape[0]\n",
    "#         current_weight = weights[trace_indices][i]\n",
    "\n",
    "#         num_unk = (trace[i] == unk).all(axis=1).sum()\n",
    "\n",
    "#         current_weights = [current_weight] * (num_triples-num_unk)\n",
    "\n",
    "#         while len(current_weights) != num_triples:\n",
    "\n",
    "#             current_weights.append(unk_weight_str)\n",
    "            \n",
    "#         per_trace_weights.append(current_weights)\n",
    "          \n",
    "#     per_trace_weights = np.array(per_trace_weights)\n",
    "    \n",
    "#     while per_trace_weights.shape[0] != longest_trace:\n",
    "#         per_trace_weights = np.concatenate([per_trace_weights,unk_weight],axis=0)\n",
    "        \n",
    "#     padded_trace = utils.pad_trace(trace,max_padding=max_padding,longest_trace=longest_trace,unk=unk)\n",
    "    \n",
    "#     processed_triples.append(triple)\n",
    "#     processed_traces.append(padded_trace)\n",
    "#     processed_weights.append(per_trace_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-somerset",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_triples = np.array(processed_triples)\n",
    "# all_traces = np.array(processed_traces)\n",
    "# all_weights = np.array(processed_weights)\n",
    "#traces: (NUM_TRIPLES,LONGEST_TRACE,MAX_PADDING,3)\n",
    "#weights: (NUM_TRIPLES,LONGEST_TRACE,MAX_PADDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-sally",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-receiver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-admission",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 2\n",
    "# current_traces = all_traces[idx]\n",
    "# current_weights = all_weights[idx]\n",
    "\n",
    "### pred_exp = np.array([['<http://example.org/data#MotherPaul>', 'child',\n",
    "#          '<http://example.org/data#BrotherPaul>'],\n",
    "#         ['<http://example.org/data#FatherPaul>', 'child',\n",
    "#          '<http://example.org/data#BrotherPaul>']\n",
    "#         ])\n",
    "\n",
    "# pred_exp = np.array(\n",
    "#     [['<http://example.org/data#MotherPaul>', 'spouse',\n",
    "#          '<http://example.org/data#FatherPaul>']])\n",
    "# def precision_recall(pred_exp,current_traces,current_weights):\n",
    "    \n",
    "#     n = len(pred_exp)\n",
    "\n",
    "#     relevance_scores = np.zeros(longest_trace) #numerator of graded recall\n",
    "\n",
    "#     for i in range(n):\n",
    "\n",
    "#         current_pred = pred_exp[i]\n",
    "\n",
    "#         for j in range(len(current_traces)):\n",
    "\n",
    "#             unpadded_traces = remove_padding_np(current_traces[j],'UNK_ENT','UNK_REL')\n",
    "#             unpadded_weights = current_weights[j][current_weights[j] != 'UNK_WEIGHT']\n",
    "\n",
    "#             indices = (unpadded_traces == current_pred).all(axis=1)\n",
    "\n",
    "#             sum_weights = sum([float(num) for num in unpadded_weights[indices]])\n",
    "\n",
    "#             relevance_scores[j] += sum_weights\n",
    "\n",
    "#     max_relevance_score = max(relevance_scores)\n",
    "#     max_idx = np.argmax(relevance_scores)\n",
    "\n",
    "#     total_sum = sum([float(weight) for weight in current_weights[max_idx] if weight != 'UNK_WEIGHT'])\n",
    "\n",
    "#     precision = max_relevance_score/n\n",
    "#     recall = max_relevance_score/total_sum\n",
    "    \n",
    "#     return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-eleven",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-shirt",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-vancouver",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d1,d2,_ = (all_traces[2] != ['UNK_ENT','UNK_REL','UNK_ENT']).nonzero()\n",
    "#all_traces[2][d1,d2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-danger",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_pred_exp = tf.convert_to_tensor(pred_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-mixture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_traces_i = tf.convert_to_tensor(all_traces[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-south",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-belly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#triples2idx = utils.array2idx(all_triples,ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traces2idx = utils.array2idx(all_traces,ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-receiver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-match",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RGCN.get_RGCN_Model(\n",
    "#     num_entities=NUM_ENTITIES,\n",
    "#     num_relations=NUM_RELATIONS,\n",
    "#     embedding_dim=10,\n",
    "#     output_dim=10,\n",
    "#     seed=123\n",
    "# )\n",
    "\n",
    "# model.load_weights(os.path.join('..','data','weights',DATASET,DATASET+'_'+RULE+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_INDICES = tf.reshape(tf.range(0,NUM_ENTITIES,1,dtype=tf.int64), (1,-1))\n",
    "\n",
    "# ADJACENCY_DATA = tf.concat([triples2idx,traces2idx.reshape(-1,3)],axis=0)\n",
    "# adj_mats = utils.get_adj_mats(ADJACENCY_DATA,NUM_ENTITIES,NUM_RELATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-conflict",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-musician",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-nightlife",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordered-quick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
