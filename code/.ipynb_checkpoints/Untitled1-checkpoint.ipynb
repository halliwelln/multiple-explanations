{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "buried-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "intermediate-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'paul'\n",
    "RULES = ['brother','sister','spouse','grandparent','parent','child','aunt','uncle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-ontario",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "champion-bryan",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PADDING = 2\n",
    "\n",
    "UNK = np.array([['UNK_ENT','UNK_REL','UNK_ENT']])\n",
    "UNK_WEIGHT_STR = 'UNK_WEIGHT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "inside-conclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "all_triples = []\n",
    "all_traces = []\n",
    "all_weights = []\n",
    "\n",
    "for rule in RULES:\n",
    "\n",
    "    if rule == 'uncle' or rule == 'aunt':\n",
    "        rule_file = 'uncle_aunt'\n",
    "\n",
    "    elif rule == 'brother' or rule == 'sister':\n",
    "        rule_file = 'brother_sister'\n",
    "        MAX_PADDING = 3\n",
    "    else:\n",
    "        rule_file = rule\n",
    "\n",
    "    triples,traces, weights = utils.parse_ttl(\n",
    "        file_name=os.path.join('..','data',f'{DATASET}_traces',f'{rule_file}.ttl'),\n",
    "        max_padding=MAX_PADDING\n",
    "    )\n",
    "\n",
    "    _, unique_traces_idx = np.unique(traces, axis=0,return_index=True)\n",
    "\n",
    "    triples = triples[unique_traces_idx]\n",
    "    traces = traces[unique_traces_idx]\n",
    "    weights = weights[unique_traces_idx]\n",
    "\n",
    "    if rule_file == 'brother_sister':\n",
    "\n",
    "        gender_indices = (traces[:,:,1] == 'gender').any(axis=1)\n",
    "\n",
    "        triples = triples[~gender_indices]\n",
    "        traces = traces[~gender_indices]\n",
    "        weights = weights[~gender_indices]\n",
    "\n",
    "        MAX_PADDING = 2\n",
    "\n",
    "        traces = traces[:,0:MAX_PADDING,:]\n",
    "\n",
    "    _, unique_triples_idx = np.unique(triples,axis=0,return_index=True)\n",
    "\n",
    "    triple_lookup = {}\n",
    "    longest_trace = -1\n",
    "\n",
    "    for i in unique_triples_idx:\n",
    "\n",
    "        triple = triples[i]\n",
    "\n",
    "        indices = (triples == triple).all(axis=1)\n",
    "\n",
    "        triple_lookup[str(triple)] = indices\n",
    "\n",
    "        sum_indices = indices.sum()\n",
    "\n",
    "        if sum_indices > longest_trace:\n",
    "\n",
    "            longest_trace = sum_indices\n",
    "\n",
    "    processed_triples = []\n",
    "    processed_weights = []\n",
    "    processed_traces = []\n",
    "\n",
    "    for idx in unique_triples_idx:\n",
    "\n",
    "        triple = triples[idx]\n",
    "\n",
    "        trace_indices = triple_lookup[str(triple)]\n",
    "        trace = traces[trace_indices]\n",
    "        weight = weights[trace_indices]\n",
    "\n",
    "        per_trace_weights = []\n",
    "\n",
    "        for i in range(len(trace)):\n",
    "\n",
    "            num_triples = trace[i].shape[0]\n",
    "            current_weight = weights[trace_indices][i]\n",
    "\n",
    "            num_unk = (trace[i] == UNK).all(axis=1).sum()\n",
    "\n",
    "            current_weights = [current_weight] * (num_triples-num_unk)\n",
    "\n",
    "            while len(current_weights) != num_triples:\n",
    "\n",
    "                current_weights.append(UNK_WEIGHT_STR)\n",
    "\n",
    "            per_trace_weights.append(current_weights)\n",
    "\n",
    "        per_trace_weights = np.array(per_trace_weights)\n",
    "\n",
    "        unk_weight = np.array([[UNK_WEIGHT_STR] * per_trace_weights.shape[1]])\n",
    "\n",
    "        while per_trace_weights.shape[0] != longest_trace:\n",
    "            per_trace_weights = np.concatenate([per_trace_weights,unk_weight],axis=0)\n",
    "\n",
    "        padded_trace = utils.pad_trace(trace,max_padding=MAX_PADDING,longest_trace=longest_trace,unk=UNK)\n",
    "\n",
    "        processed_triples.append(triple)\n",
    "        processed_traces.append(padded_trace)\n",
    "        processed_weights.append(per_trace_weights)\n",
    "\n",
    "    triples = np.array(processed_triples)\n",
    "    traces = np.array(processed_traces)\n",
    "    weights = np.array(processed_weights)\n",
    "\n",
    "    del processed_triples\n",
    "    del processed_traces\n",
    "    del processed_weights\n",
    "\n",
    "    idx = triples[:,1] == rule\n",
    "\n",
    "    triples = triples[idx]\n",
    "    traces = traces[idx]\n",
    "    weights = weights[idx]\n",
    "\n",
    "    exp_entities = np.array([\n",
    "        [traces[:,i,j,0],traces[:,i,j,2]] for i in range(longest_trace) for j in range(MAX_PADDING)]).flatten()\n",
    "\n",
    "    exp_relations = np.array([\n",
    "        [traces[:,i,j,1]] for i in range(longest_trace) for j in range(MAX_PADDING)]).flatten()\n",
    "\n",
    "    all_triples.append(triples)\n",
    "    all_traces.append(traces)\n",
    "    all_weights.append(weights)\n",
    "\n",
    "    data[rule + '_triples'] = triples\n",
    "    data[rule + '_traces'] = traces\n",
    "    data[rule + '_weights'] = weights\n",
    "    data[rule + '_entities'] = np.unique(np.concatenate([triples[:,0], triples[:,2], exp_entities],axis=0))\n",
    "    data[rule + '_relations'] = np.unique(np.concatenate([triples[:,1], exp_relations],axis=0))\n",
    "    data[rule + '_longest_trace'] = longest_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "processed-modification",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_WEIGHT = np.array([[UNK_WEIGHT_STR] * MAX_PADDING])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "seven-strengthening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_triples shape: (106, 3)\n",
      "all_traces shape: (106, 7, 2, 3)\n",
      "all_weights shape: (106, 7, 2)\n"
     ]
    }
   ],
   "source": [
    "MAX_TRACE = max([data[rule + '_longest_trace'] for rule in RULES])\n",
    "\n",
    "all_triples = []\n",
    "all_traces = []\n",
    "all_weights = []\n",
    "\n",
    "for rule in RULES:\n",
    "\n",
    "    triple_name = rule + '_triples'\n",
    "    traces_name = rule + '_traces'\n",
    "    weights_name = rule + '_weights'\n",
    "\n",
    "    traces_i = data[traces_name]\n",
    "    weights_i = data[weights_name]\n",
    "    \n",
    "    padded_traces = []\n",
    "    padded_weights = []\n",
    "\n",
    "    for i in range(len(traces_i)):\n",
    "\n",
    "        padded_trace = utils.pad_trace(traces_i[i],MAX_TRACE,MAX_PADDING,UNK)\n",
    "        padded_weight = utils.pad_weight(weights_i[i],MAX_TRACE,UNK_WEIGHT)\n",
    "\n",
    "        padded_traces.append(padded_trace)\n",
    "        padded_weights.append(padded_weight)\n",
    "\n",
    "    all_triples.append(data[triple_name])\n",
    "    all_traces.append(np.array(padded_traces))\n",
    "    all_weights.append(np.array(padded_weights))\n",
    "\n",
    "all_triples = np.concatenate(all_triples, axis=0)\n",
    "all_traces = np.concatenate(all_traces, axis=0)\n",
    "all_weights = np.concatenate(all_weights,axis=0)\n",
    "\n",
    "data['all_triples'] = all_triples\n",
    "data['all_traces'] = all_traces\n",
    "data['all_weights'] = all_weights\n",
    "\n",
    "data['max_trace'] = MAX_TRACE\n",
    "\n",
    "print(f\"all_triples shape: {all_triples.shape}\")\n",
    "\n",
    "print(f\"all_traces shape: {all_traces.shape}\")\n",
    "\n",
    "print(f\"all_weights shape: {all_weights.shape}\")\n",
    "\n",
    "all_exp_entities = np.array([\n",
    "        [all_traces[:,i,j,0],all_traces[:,i,j,2]] for i in range(MAX_TRACE) for j in range(MAX_PADDING)]).flatten()\n",
    "\n",
    "all_exp_relations = np.array([\n",
    "        [all_traces[:,i,j,1]] for i in range(MAX_TRACE) for j in range(MAX_PADDING)]).flatten()\n",
    "\n",
    "all_entities = np.unique(np.concatenate([all_triples[:,0], all_triples[:,2], all_exp_entities],axis=0))\n",
    "all_relations = np.unique(np.concatenate([all_triples[:,1], all_exp_relations],axis=0))\n",
    "\n",
    "data['all_entities'] = all_entities\n",
    "data['all_relations'] = all_relations\n",
    "data['rules'] = RULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "described-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_exp = utils.remove_padding_np(all_traces[0][0], 'UNK_ENT','UNK_REL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prescription-report",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75, 1.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.graded_precision_recall(pred_exp,all_traces[0],all_weights[0],MAX_TRACE,'UNK_ENT','UNK_REL','UNK_WEIGHT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-tribute",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-roads",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-assembly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-bullet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-adolescent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-person",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-debut",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "valued-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = np.load(os.path.join('..','data',DATASET+'.npz'))\n",
    "\n",
    "# triples,traces,weights,entities,relations = utils.get_data(data,RULE)\n",
    "\n",
    "# NUM_ENTITIES = len(entities)\n",
    "# NUM_RELATIONS = len(relations)\n",
    "\n",
    "# ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "# rel2idx = dict(zip(relations, range(NUM_RELATIONS)))\n",
    "\n",
    "# idx2ent = dict(zip(range(NUM_ENTITIES),entities))\n",
    "# idx2rel = dict(zip(range(NUM_RELATIONS),relations))\n",
    "\n",
    "# unk_ent_id = ent2idx['UNK_ENT']\n",
    "# unk_rel_id = rel2idx['UNK_REL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "remarkable-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = np.array([.99,.99,.5,.5,.5,.99,.5,.99,.5,.99,.5,.99,.5,.99,.5,.5,.5,.99,.5,.5,.99,.99,.99,.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "editorial-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#_,unique_idx = np.unique(triples,axis=0,return_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graduate-chile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "seeing-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# triple_lookup = {}\n",
    "# longest_trace = -1\n",
    "# max_padding = 3\n",
    "\n",
    "# for i in unique_idx:\n",
    "    \n",
    "#     triple = triples[i]\n",
    "    \n",
    "#     indices = (triples == triple).all(axis=1)\n",
    "        \n",
    "#     triple_lookup[str(triple)] = indices\n",
    "    \n",
    "#     sum_indices = indices.sum()\n",
    "    \n",
    "#     if sum_indices > longest_trace:\n",
    "        \n",
    "#         longest_trace = sum_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "authentic-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_triples = []\n",
    "# processed_weights = []\n",
    "# processed_traces = []\n",
    "# unk = np.array([['UNK_ENT','UNK_REL','UNK_ENT']])\n",
    "# unk_weight_str = 'UNK_WEIGHT'\n",
    "# unk_weight = np.array([[unk_weight_str] * max_padding])\n",
    "\n",
    "# for idx in unique_idx:\n",
    "    \n",
    "#     triple = triples[idx]\n",
    "    \n",
    "#     trace_indices = triple_lookup[str(triple)]\n",
    "#     trace = traces[trace_indices]\n",
    "#     weight = weights[trace_indices]\n",
    "    \n",
    "#     per_trace_weights = []\n",
    "\n",
    "#     for i in range(len(trace)):\n",
    "\n",
    "#         num_triples = trace[i].shape[0]\n",
    "#         current_weight = weights[trace_indices][i]\n",
    "\n",
    "#         num_unk = (trace[i] == unk).all(axis=1).sum()\n",
    "\n",
    "#         current_weights = [current_weight] * (num_triples-num_unk)\n",
    "\n",
    "#         while len(current_weights) != num_triples:\n",
    "\n",
    "#             current_weights.append(unk_weight_str)\n",
    "            \n",
    "#         per_trace_weights.append(current_weights)\n",
    "          \n",
    "#     per_trace_weights = np.array(per_trace_weights)\n",
    "    \n",
    "#     while per_trace_weights.shape[0] != longest_trace:\n",
    "#         per_trace_weights = np.concatenate([per_trace_weights,unk_weight],axis=0)\n",
    "        \n",
    "#     padded_trace = utils.pad_trace(trace,max_padding=max_padding,longest_trace=longest_trace,unk=unk)\n",
    "    \n",
    "#     processed_triples.append(triple)\n",
    "#     processed_traces.append(padded_trace)\n",
    "#     processed_weights.append(per_trace_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-interference",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "electrical-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_triples = np.array(processed_triples)\n",
    "# all_traces = np.array(processed_traces)\n",
    "# all_weights = np.array(processed_weights)\n",
    "#traces: (NUM_TRIPLES,LONGEST_TRACE,MAX_PADDING,3)\n",
    "#weights: (NUM_TRIPLES,LONGEST_TRACE,MAX_PADDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-proposition",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-amino",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-ending",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "valid-yeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 2\n",
    "# current_traces = all_traces[idx]\n",
    "# current_weights = all_weights[idx]\n",
    "\n",
    "### pred_exp = np.array([['<http://example.org/data#MotherPaul>', 'child',\n",
    "#          '<http://example.org/data#BrotherPaul>'],\n",
    "#         ['<http://example.org/data#FatherPaul>', 'child',\n",
    "#          '<http://example.org/data#BrotherPaul>']\n",
    "#         ])\n",
    "\n",
    "# pred_exp = np.array(\n",
    "#     [['<http://example.org/data#MotherPaul>', 'spouse',\n",
    "#          '<http://example.org/data#FatherPaul>']])\n",
    "# def precision_recall(pred_exp,current_traces,current_weights):\n",
    "    \n",
    "#     n = len(pred_exp)\n",
    "\n",
    "#     relevance_scores = np.zeros(longest_trace) #numerator of graded recall\n",
    "\n",
    "#     for i in range(n):\n",
    "\n",
    "#         current_pred = pred_exp[i]\n",
    "\n",
    "#         for j in range(len(current_traces)):\n",
    "\n",
    "#             unpadded_traces = remove_padding_np(current_traces[j],'UNK_ENT','UNK_REL')\n",
    "#             unpadded_weights = current_weights[j][current_weights[j] != 'UNK_WEIGHT']\n",
    "\n",
    "#             indices = (unpadded_traces == current_pred).all(axis=1)\n",
    "\n",
    "#             sum_weights = sum([float(num) for num in unpadded_weights[indices]])\n",
    "\n",
    "#             relevance_scores[j] += sum_weights\n",
    "\n",
    "#     max_relevance_score = max(relevance_scores)\n",
    "#     max_idx = np.argmax(relevance_scores)\n",
    "\n",
    "#     total_sum = sum([float(weight) for weight in current_weights[max_idx] if weight != 'UNK_WEIGHT'])\n",
    "\n",
    "#     precision = max_relevance_score/n\n",
    "#     recall = max_relevance_score/total_sum\n",
    "    \n",
    "#     return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-wallet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-dress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "diagnostic-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d1,d2,_ = (all_traces[2] != ['UNK_ENT','UNK_REL','UNK_ENT']).nonzero()\n",
    "#all_traces[2][d1,d2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "extra-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "assured-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_pred_exp = tf.convert_to_tensor(pred_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "synthetic-ecology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_traces_i = tf.convert_to_tensor(all_traces[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-silver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-tuesday",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "engaged-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#triples2idx = utils.array2idx(all_triples,ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "broke-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traces2idx = utils.array2idx(all_traces,ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-evening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "taken-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "incorrect-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RGCN.get_RGCN_Model(\n",
    "#     num_entities=NUM_ENTITIES,\n",
    "#     num_relations=NUM_RELATIONS,\n",
    "#     embedding_dim=10,\n",
    "#     output_dim=10,\n",
    "#     seed=123\n",
    "# )\n",
    "\n",
    "# model.load_weights(os.path.join('..','data','weights',DATASET,DATASET+'_'+RULE+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "stable-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_INDICES = tf.reshape(tf.range(0,NUM_ENTITIES,1,dtype=tf.int64), (1,-1))\n",
    "\n",
    "# ADJACENCY_DATA = tf.concat([triples2idx,traces2idx.reshape(-1,3)],axis=0)\n",
    "# adj_mats = utils.get_adj_mats(ADJACENCY_DATA,NUM_ENTITIES,NUM_RELATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-fortune",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-carpet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-robertson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-floor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
