{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "terminal-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import utils\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-reverse",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'french_royalty'\n",
    "rules = ['child','parent','spouse','brother','sister','grandparent', 'full_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = dict(zip(rules,np.zeros(len(rules))))\n",
    "counts['UNK_REL'] = 0\n",
    "\n",
    "for rule in rules:\n",
    "    \n",
    "    data = np.load(os.path.join('..','data',DATASET+'.npz'))\n",
    "\n",
    "    triples,traces,weights,entities,relations = utils.get_data(data,rule)\n",
    "    \n",
    "    num_triples = triples.shape[0]\n",
    "    \n",
    "    print(f'{rule}: {num_triples}')\n",
    "    counts[rule] += triples.shape[0]\n",
    "    counts[rule + '_num_entities'] = len(entities)\n",
    "\n",
    "    for i in range(len(traces)):\n",
    "\n",
    "        for j in range(len(traces[i])):\n",
    "            \n",
    "            for k in range(len(traces[i,j])):\n",
    "                \n",
    "                rel = traces[i,j,k][1]\n",
    "                \n",
    "                counts[rel] += 1\n",
    "            \n",
    "#             rels = traces[i,j][:,1]\n",
    "        \n",
    "#             if (rels == 'UNK_REL').sum() != 2 :\n",
    "\n",
    "#                 rels = '_'.join(rels)\n",
    "                \n",
    "#                 if rels in counts:\n",
    "#                     counts[rels] += 1\n",
    "#                 else:\n",
    "#                     counts[rels] = 1\n",
    "#     print('\\n')              \n",
    "#     print(f'rule {rule} counts: {counts}')\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-record",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for rule in rules:\n",
    "    total += counts[rule]\n",
    "total - counts['full_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attached-bathroom",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-volleyball",
   "metadata": {},
   "outputs": [],
   "source": [
    "(traces[i][0] != unk).all(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk = np.array([['UNK_ENT', 'UNK_REL', 'UNK_ENT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "327 / (327 + 41 + 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_true_triples = []\n",
    "\n",
    "# for i in range(len(traces)):\n",
    "#     num_explanations = 0\n",
    "#     for j in range(len(traces[i])):\n",
    "\n",
    "#         current_trace = traces[i][j]\n",
    "\n",
    "#         num_triples = (current_trace != unk).all(axis=1).sum()\n",
    "\n",
    "#         if  num_triples > 0:\n",
    "#             num_explanations += 1\n",
    "#             num_true_triples.append(num_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspended-remains",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "foreign-coffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'french_royalty'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "associate-folks",
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'spouse'    \n",
    "\n",
    "data = np.load(os.path.join('..','data',DATASET+'.npz'))\n",
    "\n",
    "triples,traces,weights,entities,relations = utils.get_data(data,RULE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "moral-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "explaine_data = np.load(\n",
    "    os.path.join('..','data','preds',DATASET,\n",
    "        'explaine_'+DATASET+'_'+RULE+'_preds.npz'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "starting-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "explaine_test_idx = explaine_data['test_idx']\n",
    "\n",
    "explaine_true_exps = traces[explaine_test_idx]\n",
    "explaine_true_weights = weights[explaine_test_idx]\n",
    "\n",
    "explaine_preds = explaine_data['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incomplete-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "explaine_true_exp = explaine_true_exps[i]\n",
    "explaine_pred = explaine_preds[i]\n",
    "true_weight = explaine_true_weights[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-family",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "humanitarian-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(explaine_pred)\n",
    "\n",
    "unk = np.array([['UNK_ENT', 'UNK_REL', 'UNK_ENT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "documentary-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_true_triples = []\n",
    "num_explanations = 0\n",
    "\n",
    "for i in range(len(explaine_true_exp)):\n",
    "\n",
    "    current_trace = explaine_true_exp[i]\n",
    "\n",
    "    num_triples = (current_trace != unk).all(axis=1).sum()\n",
    "\n",
    "    if  num_triples > 0:\n",
    "        \n",
    "        num_explanations += 1\n",
    "        num_true_triples.append(num_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "shaped-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_scores = np.zeros(num_explanations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "thrown-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "\n",
    "    current_pred = explaine_pred[i]\n",
    "\n",
    "    for j in range(num_explanations):\n",
    "\n",
    "        unpadded_traces = utils.remove_padding_np(explaine_true_exp[j],'UNK_ENT','UNK_REL')\n",
    "\n",
    "        unpadded_weights = true_weight[j][true_weight[j] != 'UNK_WEIGHT']\n",
    "\n",
    "        indices = (unpadded_traces == current_pred).all(axis=1)\n",
    "\n",
    "        sum_weights = sum([float(num) for num in unpadded_weights[indices]])\n",
    "\n",
    "        relevance_scores[j] += sum_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "representative-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_true_triples = np.array(num_true_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "built-cream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.5       , 0.        , 0.        , 0.44444444])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_scores / (n * .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "apart-pearl",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.5       , 0.        , 0.        , 0.88888889])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevance_scores / (num_true_triples * .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-addiction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-tulsa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-america",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "triples[:,1] == 'spouse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "explaine_data = np.load(\n",
    "    os.path.join('..','data','preds',DATASET,\n",
    "        'explaine_'+DATASET+'_'+RULE+'_preds.npz'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simplified-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "explaine_test_idx = explaine_data['test_idx']\n",
    "explaine_true_triples = triples[explaine_test_idx]\n",
    "explaine_true_exps = traces[explaine_test_idx]\n",
    "explaine_preds = explaine_data['preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 102\n",
    "print(explaine_true_triples[i])\n",
    "print(explaine_preds[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technological-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'spouse_spouse': 327, 'spouse_child_child': 41, 'spouse_child_parent': 23}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = ['_'.join(k.split('_')[1:]) for k,_ in d.items()]\n",
    "values = list(d.values())\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "ax.bar(keys,values)\n",
    "ax.set_xticklabels(labels=keys,rotation = (45), fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_data = np.load(\n",
    "    os.path.join('..','data','preds',DATASET,\n",
    "        'gnn_explainer_'+DATASET+'_'+RULE+'_preds.npz'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_ENT_ID = 'UNK_ENT'\n",
    "UNK_REL_ID = 'UNK_REL'\n",
    "UNK_WEIGHT_ID = 'UNK_WEIGHT'\n",
    "MAX_TRACE = data['max_trace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_test_idx = gnn_data['test_idx']\n",
    "gnn_true_triples = triples[gnn_test_idx]\n",
    "gnn_true_exps = traces[gnn_test_idx]\n",
    "gnn_true_weights = weights[gnn_test_idx]\n",
    "\n",
    "gnn_preds = gnn_data['preds']\n",
    "\n",
    "num_gnn_triples = gnn_true_exps.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicate_counts = {}\n",
    "correct_counts = {}\n",
    "for i in range(num_gnn_triples):\n",
    "    \n",
    "    gnn_true_triple = gnn_true_triples[i]\n",
    "    gnn_true_exp = gnn_true_exps[i]\n",
    "    gnn_pred = gnn_preds[i]\n",
    "    true_weight = gnn_true_weights[i]\n",
    "    \n",
    "    max_jaccard,max_idx = utils.max_jaccard_np(gnn_true_exp,gnn_pred,UNK_ENT_ID,UNK_REL_ID,return_idx=True)\n",
    "    \n",
    "    max_predicates = gnn_true_triple[1] +'_' + '_'.join([p for p in gnn_true_exp[max_idx,:,1] if p != 'UNK_REL'])\n",
    "    \n",
    "    if max_jaccard < 1:\n",
    "\n",
    "        if max_predicates in predicate_counts:\n",
    "            predicate_counts[max_predicates] += 1\n",
    "        else:\n",
    "            predicate_counts[max_predicates] = 1\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if max_predicates in correct_counts:\n",
    "            correct_counts[max_predicates] += 1\n",
    "        else:\n",
    "            correct_counts[max_predicates] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('..','data','predicate_weights.json'),'r') as f:\n",
    "    predicate_weights = json.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_counts = {}\n",
    "\n",
    "for k,count in predicate_counts.items():\n",
    "    \n",
    "    str_weight = predicate_weights[k]\n",
    "    \n",
    "    if str_weight in weight_counts:\n",
    "        weight_counts[str_weight] += count\n",
    "    else:\n",
    "        weight_counts[str_weight] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-alaska",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_weight_counts = {}\n",
    "\n",
    "for k,count in correct_counts.items():\n",
    "    \n",
    "    str_weight = predicate_weights[k]\n",
    "    \n",
    "    if str_weight in correct_weight_counts:\n",
    "        correct_weight_counts[str_weight] += count\n",
    "    else:\n",
    "        correct_weight_counts[str_weight] = count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight_sum = []\n",
    "\n",
    "# for i in range(len(weights[0])):\n",
    "    \n",
    "#     summm = 0.0\n",
    "    \n",
    "#     for j in weights[0][i]:\n",
    "        \n",
    "#         if j != 'UNK_WEIGHT':\n",
    "#             summm += float(j)\n",
    "#     weight_sum.append(summm)\n",
    "\n",
    "# weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(predicate_weights.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-oxford",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-huntington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-extreme",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-handling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-simon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "#['UNK_REL', 'child', 'parent', 'spouse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# explaine_data = np.load(\n",
    "#     os.path.join('..','data','preds',DATASET,\n",
    "#         'explaine_'+DATASET+'_'+RULE+'_preds.npz'),allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-catholic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "#triples[(triples[:,0] == '<http://dbpedia.org/resource/Louis_VII_of_France>')][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [['<http://dbpedia.org/resource/Agnes_of_France,_Byzantine_Empress>',\n",
    "#          'grandparent',\n",
    "#          '<http://dbpedia.org/resource/Louis_VI_of_France>'],\n",
    "#         ['<http://dbpedia.org/resource/Louis_VII_of_France>', 'parent',\n",
    "#          '<http://dbpedia.org/resource/Louis_VI_of_France>']],\n",
    "\n",
    "# array([[['<http://dbpedia.org/resource/Adela_of_Champagne>', 'child',\n",
    "#          '<http://dbpedia.org/resource/Agnes_of_France,_Byzantine_Empress>'],\n",
    "#         ['<http://dbpedia.org/resource/Louis_VII_of_France>', 'spouse',\n",
    "#          '<http://dbpedia.org/resource/Adela_of_Champagne>']],\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traces[(triples[:,0] == '<http://dbpedia.org/resource/Louis_VII_of_France>')][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import RGCN\n",
    "\n",
    "RULE = 'full_data'\n",
    "\n",
    "full_data = np.load(os.path.join('..','data',DATASET+'.npz'))\n",
    "\n",
    "full_triples,full_traces,full_weights,full_entities,full_relations = utils.get_data(full_data,RULE)\n",
    "\n",
    "full_model = RGCN.get_RGCN_Model(\n",
    "    num_entities=len(full_entities),\n",
    "    num_relations=len(full_relations),\n",
    "    embedding_dim=10,\n",
    "    output_dim=10,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "NUM_ENTITIES_FULL = len(full_entities)\n",
    "NUM_RELATIONS_FULL = len(full_relations)\n",
    "\n",
    "full_ent2idx = dict(zip(full_entities, range(NUM_ENTITIES_FULL)))\n",
    "full_rel2idx = dict(zip(full_relations, range(NUM_RELATIONS_FULL)))\n",
    "\n",
    "full_model.load_weights(os.path.join('..','data','weights',DATASET,DATASET+'_'+RULE+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_embeddings = full_model.get_layer('entity_embeddings').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "RULE = 'full_data'\n",
    "\n",
    "data = np.load(os.path.join('..','data',DATASET+'.npz'))\n",
    "\n",
    "triples,traces,weights,entities,relations = utils.get_data(data,RULE)\n",
    "\n",
    "model = RGCN.get_RGCN_Model(\n",
    "    num_entities=len(entities),\n",
    "    num_relations=len(relations),\n",
    "    embedding_dim=10,\n",
    "    output_dim=10,\n",
    "    seed=123\n",
    ")\n",
    "\n",
    "\n",
    "NUM_ENTITIES = len(entities)\n",
    "NUM_RELATIONS = len(relations)\n",
    "\n",
    "ent2idx = dict(zip(entities, range(NUM_ENTITIES)))\n",
    "rel2idx = dict(zip(relations, range(NUM_RELATIONS)))\n",
    "\n",
    "model.load_weights(os.path.join('..','data','weights',DATASET,DATASET+'_'+RULE+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historic-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "spouse_embeddings = model.get_layer('entity_embeddings').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-placement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect, comm1, comm2 = np.intersect1d(full_entities,entities,return_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-speech",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-creation",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = np.sum(np.square(full_embeddings[comm1]), axis=1)[:,np.newaxis]\n",
    "YY = np.sum(np.square(spouse_embeddings), axis=1)\n",
    "\n",
    "distances = XX + YY - 2 * np.dot(full_embeddings[comm1], spouse_embeddings.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-minority",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-sample",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-investigator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "miniature-genome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-theorem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statutory-interface",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-coordination",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-capacity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, XML\n",
    "from rdflib import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 1000\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql = SPARQLWrapper(\"http://dbpedia.org/sparql\")\n",
    "sparql.setQuery(f\"\"\"\n",
    "    PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "    PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "    CONSTRUCT{{\n",
    "    ?x\n",
    "    dbo:child ?child .\n",
    "    }}\n",
    "    WHERE {{\n",
    "    ?x a dbo:Royalty .\n",
    "    OPTIONAL {{?x dbo:child ?child }}\n",
    "    }}\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-assessment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-religious",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql.setReturnFormat(XML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sparql.query().convert().serialize(destination='/Users/nhalliwe/Desktop/test',\n",
    "            format='xml'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "# PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "\n",
    "# CONSTRUCT{ \n",
    "#      ?x dbo:parent ?parent ;\n",
    "#      dbo:child ?child ;\n",
    "#      dbo:spouse ?spouse ;\n",
    "#      foaf:gender ?gender ;\n",
    "#  }\n",
    "# WHERE {\n",
    "#   OPTIONAL {?x dbo:parent ?parent }\n",
    "#   OPTIONAL {?x dbo:spouse ?spousea }\n",
    "#   OPTIONAL {?x foaf:gender ?gender }\n",
    "#   OPTIONAL {?x dbo:child ?child } \n",
    "\n",
    "#   FILTER regex(?x,\"England\")\n",
    "# }\n",
    "#rename file with .ttl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "# PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "\n",
    "# CONSTRUCT{ \n",
    "#      ?x dbo:parent ?parent ;\n",
    "#      dbo:child ?child ;\n",
    "#      dbo:spouse ?spouse ;\n",
    "#      foaf:gender ?gender ;\n",
    "#  }\n",
    "# WHERE {\n",
    "#   ?x dbo:parent ?parent .\n",
    "#   ?x dbo:spouse ?spouse .\n",
    "#   ?x foaf:gender ?gender .\n",
    "#   ?x dbo:child ?child .\n",
    "\n",
    "#   FILTER regex(?x,\"England\")\n",
    "# }\n",
    "#small english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-crash",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdflib import Graph\n",
    "from rdflib import plugin\n",
    "import rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "plugin.register(\n",
    "    'sparql', rdflib.query.Processor,\n",
    "    'rdfextras.sparql.processor', 'Processor')\n",
    "plugin.register(\n",
    "    'sparql', rdflib.query.Result,\n",
    "    'rdfextras.sparql.query', 'SPARQLQueryResult')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph(base='http://www.w3.org/2000/01/rdf-schema#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.parse('/Users/nhalliwe/Desktop/full_test',format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "PREFIX dbo: <http://dbpedia.org/ontology/>\n",
    "PREFIX foaf: <http://xmlns.com/foaf/0.1/>\n",
    "    \n",
    "CONSTRUCT{{\n",
    "    ?x\n",
    "    dbo:parent ?parent ;\n",
    "    dbo:child ?child ;\n",
    "    dbo:spouse ?spouse ;\n",
    "    foaf:gender ?gender .\n",
    "    }}\n",
    "WHERE {{\n",
    "    ?x a dbo:Royalty .\n",
    "    OPTIONAL {{?x dbo:parent ?parent }}\n",
    "    OPTIONAL {{?x dbo:spouse ?spouse }}\n",
    "    OPTIONAL {{?x foaf:gender ?gender }}\n",
    "    OPTIONAL {{?x dbo:child ?child }}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-spirituality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for row in g.query(query):µ\n",
    "#     print(row['*'])\n",
    "\n",
    "g.query(query)#.serialize(destination='/Users/nhalliwe/Desktop/test',format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.parse('/Users/nhalliwe/Desktop/Explain-KG/data/rules/full_royalty',format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-double",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.parse('/Users/nhalliwe/Desktop/test',format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g.serialize(destination='/Users/nhalliwe/Desktop/full_test',format='xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-mustang",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-overall",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-northern",
   "metadata": {},
   "outputs": [],
   "source": [
    "# triple_lookup = {}\n",
    "# longest_trace = -1\n",
    "# max_padding = 3\n",
    "\n",
    "# for i in unique_idx:\n",
    "    \n",
    "#     triple = triples[i]\n",
    "    \n",
    "#     indices = (triples == triple).all(axis=1)\n",
    "        \n",
    "#     triple_lookup[str(triple)] = indices\n",
    "    \n",
    "#     sum_indices = indices.sum()\n",
    "    \n",
    "#     if sum_indices > longest_trace:\n",
    "        \n",
    "#         longest_trace = sum_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_triples = []\n",
    "# processed_weights = []\n",
    "# processed_traces = []\n",
    "# unk = np.array([['UNK_ENT','UNK_REL','UNK_ENT']])\n",
    "# unk_weight_str = 'UNK_WEIGHT'\n",
    "# unk_weight = np.array([[unk_weight_str] * max_padding])\n",
    "\n",
    "# for idx in unique_idx:\n",
    "    \n",
    "#     triple = triples[idx]\n",
    "    \n",
    "#     trace_indices = triple_lookup[str(triple)]\n",
    "#     trace = traces[trace_indices]\n",
    "#     weight = weights[trace_indices]\n",
    "    \n",
    "#     per_trace_weights = []\n",
    "\n",
    "#     for i in range(len(trace)):\n",
    "\n",
    "#         num_triples = trace[i].shape[0]\n",
    "#         current_weight = weights[trace_indices][i]\n",
    "\n",
    "#         num_unk = (trace[i] == unk).all(axis=1).sum()\n",
    "\n",
    "#         current_weights = [current_weight] * (num_triples-num_unk)\n",
    "\n",
    "#         while len(current_weights) != num_triples:\n",
    "\n",
    "#             current_weights.append(unk_weight_str)\n",
    "            \n",
    "#         per_trace_weights.append(current_weights)\n",
    "          \n",
    "#     per_trace_weights = np.array(per_trace_weights)\n",
    "    \n",
    "#     while per_trace_weights.shape[0] != longest_trace:\n",
    "#         per_trace_weights = np.concatenate([per_trace_weights,unk_weight],axis=0)\n",
    "        \n",
    "#     padded_trace = utils.pad_trace(trace,max_padding=max_padding,longest_trace=longest_trace,unk=unk)\n",
    "    \n",
    "#     processed_triples.append(triple)\n",
    "#     processed_traces.append(padded_trace)\n",
    "#     processed_weights.append(per_trace_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-personality",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-assignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_triples = np.array(processed_triples)\n",
    "# all_traces = np.array(processed_traces)\n",
    "# all_weights = np.array(processed_weights)\n",
    "#traces: (NUM_TRIPLES,LONGEST_TRACE,MAX_PADDING,3)\n",
    "#weights: (NUM_TRIPLES,LONGEST_TRACE,MAX_PADDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-visit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-cream",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-august",
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 2\n",
    "# current_traces = all_traces[idx]\n",
    "# current_weights = all_weights[idx]\n",
    "\n",
    "### pred_exp = np.array([['<http://example.org/data#MotherPaul>', 'child',\n",
    "#          '<http://example.org/data#BrotherPaul>'],\n",
    "#         ['<http://example.org/data#FatherPaul>', 'child',\n",
    "#          '<http://example.org/data#BrotherPaul>']\n",
    "#         ])\n",
    "\n",
    "# pred_exp = np.array(\n",
    "#     [['<http://example.org/data#MotherPaul>', 'spouse',\n",
    "#          '<http://example.org/data#FatherPaul>']])\n",
    "# def precision_recall(pred_exp,current_traces,current_weights):\n",
    "    \n",
    "#     n = len(pred_exp)\n",
    "\n",
    "#     relevance_scores = np.zeros(longest_trace) #numerator of graded recall\n",
    "\n",
    "#     for i in range(n):\n",
    "\n",
    "#         current_pred = pred_exp[i]\n",
    "\n",
    "#         for j in range(len(current_traces)):\n",
    "\n",
    "#             unpadded_traces = remove_padding_np(current_traces[j],'UNK_ENT','UNK_REL')\n",
    "#             unpadded_weights = current_weights[j][current_weights[j] != 'UNK_WEIGHT']\n",
    "\n",
    "#             indices = (unpadded_traces == current_pred).all(axis=1)\n",
    "\n",
    "#             sum_weights = sum([float(num) for num in unpadded_weights[indices]])\n",
    "\n",
    "#             relevance_scores[j] += sum_weights\n",
    "\n",
    "#     max_relevance_score = max(relevance_scores)\n",
    "#     max_idx = np.argmax(relevance_scores)\n",
    "\n",
    "#     total_sum = sum([float(weight) for weight in current_weights[max_idx] if weight != 'UNK_WEIGHT'])\n",
    "\n",
    "#     precision = max_relevance_score/n\n",
    "#     recall = max_relevance_score/total_sum\n",
    "    \n",
    "#     return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-antibody",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-bahrain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d1,d2,_ = (all_traces[2] != ['UNK_ENT','UNK_REL','UNK_ENT']).nonzero()\n",
    "#all_traces[2][d1,d2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-indian",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_pred_exp = tf.convert_to_tensor(pred_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf_traces_i = tf.convert_to_tensor(all_traces[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-option",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-editing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-memorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "#triples2idx = utils.array2idx(all_triples,ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "#traces2idx = utils.array2idx(all_traces,ent2idx,rel2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-carrier",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "original-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RGCN.get_RGCN_Model(\n",
    "#     num_entities=NUM_ENTITIES,\n",
    "#     num_relations=NUM_RELATIONS,\n",
    "#     embedding_dim=10,\n",
    "#     output_dim=10,\n",
    "#     seed=123\n",
    "# )\n",
    "\n",
    "# model.load_weights(os.path.join('..','data','weights',DATASET,DATASET+'_'+RULE+'.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-spencer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL_INDICES = tf.reshape(tf.range(0,NUM_ENTITIES,1,dtype=tf.int64), (1,-1))\n",
    "\n",
    "# ADJACENCY_DATA = tf.concat([triples2idx,traces2idx.reshape(-1,3)],axis=0)\n",
    "# adj_mats = utils.get_adj_mats(ADJACENCY_DATA,NUM_ENTITIES,NUM_RELATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-salem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-storm",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-henry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-quick",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
